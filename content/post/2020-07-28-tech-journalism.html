---
title: Using Twitter to Analyze Diversity in Professional Domains (Appendix for Tech Journalism is Less Diverse than Tech)
draft: yes
author: ''
date: '2020-07-28'
slug: tech-journalism
categories:
  - theory & empirics
tags:
  - data
subtitle: ''
summary: ''
authors: []
lastmod: '2020-07-29T19:36:05-06:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---



<p>Disclosure: I conducted this analysis for <a href="https://twitter.com/balajis/status/1280261091302375424">one of Balaji Srinivasan’s contests</a> and received from him $1k in BTC.</p>
<p>Tech journalists often criticize the technology sector for a lack of racial and gender diversity. So we analyzed the diversity of tech journalists. Using multiple sampling methods, and multiple ways of measuring race and gender, we find that tech journalism is almost certainly less racially diverse than tech itself.</p>
<p>The code here may be of use to others analyzing racial and/or gender diversity in other domains as well.</p>
<p><a href="https://docs.google.com/spreadsheets/d/1c4IimnX1DpPEOTI5CLhWmxuhlaocYlFD2wy1D6i-2oQ/edit?usp=sharing">Here is the final dataset with the estimated race and gender of 982 tech journalists.</a></p>
<div id="tldr" class="section level2">
<h2>TLDR</h2>
<p>The workforce of the big five tech companies is about 51% white, averaging across each company’s most recent diversity report, linked below. Big Tech is therefore more diverse than tech journalism, which our analysis suggests to be somewhere between 77% on the low end (if we infer race from surnames of 982 Twitter accounts) and 84% white on the high end (if we check our results against third-party-curated Twitter lists of tech journalists). If we guess race from a manual, subjective assessment of the 982 Twitter accounts we identified, then it appears that 80% of tech journalists are white. The tightness of these estimates for tech journalism should inspire some confidence in their accuracy.</p>
<p>As of 2020, the percentage of White employees at Facebook is <a href="https://diversity.fb.com/read-report/">63.2%.</a> At Google, <a href="https://kstatic.googleusercontent.com/files/25badfc6b6d1b33f3b87372ff7545d79261520d821e6ee9a82c4ab2de42a01216be2156bc5a60ae3337ffe7176d90b8b2b3000891ac6e516a650ecebf0e3f866">51.7%</a>. At Microsoft, <a href="https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4aqv1">53.2%</a>. At Amazon, <a href="https://www.aboutamazon.com/working-at-amazon/diversity-and-inclusion/our-workforce-data">34.7%</a>. At Apple, <a href="https://www.apple.com/diversity/">50%</a>.</p>
</div>
<div id="background-and-overview-of-the-methodology" class="section level2">
<h2>Background and overview of the methodology</h2>
<p>The initial dataset gathered by <a href="https://twitter.com/OoTheNigerian">OoTheNigerian</a> focused on the diversity of attendees at tech-journalism conferences, but this approach has two major limitations. First, conferences are subject to a variety of selection biases, which might not have anything to do with tech-journalism culture per se. Second, there are only so many tech-journalism conferences, so this approach will likely leave us with an unnecessarily small sample.</p>
<p>Here we pursue a different approach, using multiple methods to check the robustness of our results. Thanks to OoTheNigerian for his help.</p>
</div>
<div id="two-different-sampling-methods" class="section level2">
<h2>Two different sampling methods</h2>
<p>We use two different sampling methods to make sure our results are not sensitive to how the set of “tech journalists” is defined. In a first sampling method, we collected lists of individuals on Twitter whose bios indicate current or past work for any one of 13 major tech-journalism outlets (namely Verge, Gigaom, Cnet, Wired, Engadget, The Information, Recode, The Next Web, Venture Beat, TechRadar, TechCrunch, Gizmodo, and Motherboard). We added tech journalists from the New York Times as well, see below for more details.</p>
<p>Alternatively, we also gather a dataset of tech journalists by combining two publicly available, third-party-curated lists called “Tech Journalists.” We had no role in the curation of these lists, so if the results of our diversity analysis are similar when conducted on this sample as well, we should be highly confident that our analyses accurately reflect the true state of tech journalism on Twitter.</p>
</div>
<div id="two-ways-of-estimating-race-and-gender" class="section level2">
<h2>Two ways of estimating race and gender</h2>
<p>Estimating race and gender is fraught. A method based on measurable, objective aspects of a person’s identity may fail to capture certain nuances in how race and gender are socially constructed. A method based on subjective human judgment might err by being inconsistent, ignorant, or prejudiced about how race and gender are assigned. To deal with the limitations of each method, we estimate race and gender through both methods: If the results are similar, we should be relatively confident in their accuracy.</p>
<p><em>Subjective judgment.</em> Estimating race and gender through subjective judgment was straightforward, if not always possible: We looked at each Twitter account and inferred the individual’s race and gender holistically, using their profile photo, name, and context-clues in their bio. In most cases, the inference was unambiguous. In cases where either the gender or race was unclear, we assigned an “NA” for the given variable. Given some controversy over the race of Arab and Persian people (the US census says “white” but many people have contested this), we sidestep the matter by assigning Arabs and Persians “NA” for race. (There were only about 15 total so including them would likely make tech journalism even less diverse.)</p>
<p><em>Objective judgment.</em> Alternatively, we leveraged data from the Census and the Social Security Administration to infer journalist’s race and gender from surnames and first names, respectively.</p>
</div>
<div id="note-on-the-analytic-virtue-of-using-twitter-data" class="section level2">
<h2>Note on the analytic virtue of using Twitter data</h2>
<p>While our approach certainly has its own limitations, analyzing the culture of tech journalism via Twitter-based samples seems uniquely attractive. First, it’s possible some tech journalists are not on Twitter, but since Twitter is both a hot technology and a watering-hole for journalists, this potential selection bias seems particularly unthreatening. Twitter is arguably the ideal place to draw a sample of tech journalists. A second limitation of my approach is that we may very well fail to identify some tech journalists who are on Twitter, but this is only an analytical problem if there is some reason to believe that white people or male people are more or less likely to surface in my search procedures. Assuming this is very unlikely, the worst that can be said of our sampling method is that it’s unlikely to capture every single tech journalist on Twitter. Nonetheless, it is likely to be quite close to a random sample of all the tech journalists on Twitter, which means it should plausibly generalize. If there is a non-trivial community of tech journalists not on Twitter someone should tell them about what’s new in the world of technology.</p>
</div>
<div id="note-on-inferring-race-and-gender-from-names" class="section level2">
<h2>Note on inferring race and gender from names</h2>
<p>In estimating race from surnames, the most serious problem is due to the history of anti-black racism and slavery in the United States. Because of slavery in the United States, black people in America today frequently have non-African last names (such as Williams or Washington). Therefore, inferring race from surnames will generally under-count black people. As you’ll see below, we take some extra steps to mitigate this problem (see my comments inside the code snippets), but the results of any automated measurement method will always have some amount of error. Same for gender. We believe this problem is more than off-set by using subjective judgment as an independent and alternative approach.</p>
</div>
<div id="approach-1-tech-journalists-who-mention-a-major-tech-journalism-outlet-in-their-bio" class="section level2">
<h2>Approach 1: Tech journalists who mention a major tech-journalism outlet in their bio</h2>
<p>I used the R package <em>rtweet</em> to search for anyone on Twitter who mentions one of 12 journalism-related keywords (reporter, journalist, producer, designer, editor, writer, analyst, current, former, bylines, columnist, freelance) and one of 13 tech-journalism oulets in their bio (Verge, Gigaom, Cnet, Wired, Engadget, The Information, Recode, The Next Web, Venture Beat, TechRadar, TechCrunch, Gizmodo, and Motherboard). The API allows for up to 1,000 results per search.</p>
<p>Tech journalists associated with the New York Times were added before the final analysis in a somewhat <em>ad hoc</em> fashion. We first gathered names by searching for people on Twitter with “tech” and “nytimes” (the Twitter username of the NYT), and then we manually gathered the Twitter usernames of every author listed in <a href="https://www.nytimes.com/section/technology">the Technology section</a> in the month of July.</p>
<pre class="r"><code># Load required packages 

require(rtweet)
require(tidyverse)
require(predictrace)
require(stringr)
require(gender)
require(DT)
require(grid)

# Search for accounts mentioning tech-journalism outlets 


v1 &lt;- search_users(&quot;reporter Verge&quot;, n = 1000)
v2 &lt;- search_users(&quot;journalist Verge&quot;, n = 1000)
v3 &lt;- search_users(&quot;producer Verge&quot;, n = 1000)
v4 &lt;- search_users(&quot;designer Verge&quot;, n = 1000)
v5 &lt;- search_users(&quot;editor Verge&quot;, n = 1000)
v6 &lt;- search_users(&quot;writer Verge&quot;, n = 1000)
v7 &lt;- search_users(&quot;analyst Verge&quot;, n = 1000)
v8 &lt;- search_users(&quot;current Verge&quot;, n = 1000)
v9 &lt;- search_users(&quot;former Verge&quot;, n = 1000)
v10 &lt;- search_users(&quot;bylines Verge&quot;, n = 1000)
v11 &lt;- search_users(&quot;columnist Verge&quot;, n = 1000)
v12 &lt;- search_users(&quot;freelance Verge&quot;, n = 1000)
v&lt;-rbind(v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11, v12)
v$outlet&lt;-&quot;The Verge&quot;
rm(v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11, v12)


go1 &lt;- search_users(&quot;reporter Gigaom&quot;, n = 1000)
go2 &lt;- search_users(&quot;journalist Gigaom&quot;, n = 1000)
go3 &lt;- search_users(&quot;producer Gigaom&quot;, n = 1000)
go4 &lt;- search_users(&quot;designer Gigaom&quot;, n = 1000)
go5 &lt;- search_users(&quot;editor Gigaom&quot;, n = 1000)
go6 &lt;- search_users(&quot;writer Gigaom&quot;, n = 1000)
go7 &lt;- search_users(&quot;analyst Gigaom&quot;, n = 1000)
go8 &lt;- search_users(&quot;current Gigaom&quot;, n = 1000)
go9 &lt;- search_users(&quot;former Gigaom&quot;, n = 1000)
go10 &lt;- search_users(&quot;bylines Gigaom&quot;, n = 1000)
go11 &lt;- search_users(&quot;columnist Gigaom&quot;, n = 1000)
go12 &lt;- search_users(&quot;freelance Gigaom&quot;, n = 1000)
go&lt;-rbind(go1, go2, go3, go4, go5, go6, go7, go8, go9, go10, go11, go12)
go$outlet&lt;-&quot;Gigaom&quot;
rm(go1, go2, go3, go4, go5, go6, go7, go8, go9, go10, go11, go12)

e1 &lt;- search_users(&quot;reporter Engadget&quot;, n = 1000)
e2 &lt;- search_users(&quot;journalist Engadget&quot;, n = 1000)
e3 &lt;- search_users(&quot;producer Engadget&quot;, n = 1000)
e4 &lt;- search_users(&quot;designer Engadget&quot;, n = 1000)
e5 &lt;- search_users(&quot;editor Engadget&quot;, n = 1000)
e6 &lt;- search_users(&quot;writer Engadget&quot;, n = 1000)
e7 &lt;- search_users(&quot;analyst Engadget&quot;, n = 1000)
e8 &lt;- search_users(&quot;current Engadget&quot;, n = 1000)
e9 &lt;- search_users(&quot;former Engadget&quot;, n = 1000)
e10 &lt;- search_users(&quot;bylines Engadget&quot;, n = 1000)
e11 &lt;- search_users(&quot;columnist Engadget&quot;, n = 1000)
e12 &lt;- search_users(&quot;freelance Engadget&quot;, n = 1000)
e&lt;-rbind(e1, e2, e3, e4, e5, e6, e7, e8, e9, e10, e11, e12)
e$outlet&lt;-&quot;Engadget&quot;
rm(e1, e2, e3, e4, e5, e6, e7, e8, e9, e10, e11, e12)


vb1 &lt;- search_users(&quot;reporter VentureBeat&quot;, n = 1000)
vb2 &lt;- search_users(&quot;journalist VentureBeat&quot;, n = 1000)
vb3 &lt;- search_users(&quot;producer VentureBeat&quot;, n = 1000)
vb4 &lt;- search_users(&quot;designer VentureBeat&quot;, n = 1000)
vb5 &lt;- search_users(&quot;editor VentureBeat&quot;, n = 1000)
vb6 &lt;- search_users(&quot;writer VentureBeat&quot;, n = 1000)
vb7 &lt;- search_users(&quot;analyst VentureBeat&quot;, n = 1000)
vb8 &lt;- search_users(&quot;current VentureBeat&quot;, n = 1000)
vb9 &lt;- search_users(&quot;former VentureBeat&quot;, n = 1000)
vb10 &lt;- search_users(&quot;bylines VentureBeat&quot;, n = 1000)
vb11 &lt;- search_users(&quot;columnist VentureBeat&quot;, n = 1000)
vb12 &lt;- search_users(&quot;freelance VentureBeat&quot;, n = 1000)
vb&lt;-rbind(vb1, vb2, vb3, vb4, vb5, vb6, vb7, vb8, vb9, vb10, vb11, vb12)
vb$outlet&lt;-&quot;Venture Beat&quot;
rm(vb1, vb2, vb3, vb4, vb5, vb6, vb7, vb8, vb9, vb10, vb11, vb12)


wi1 &lt;- search_users(&quot;reporter wired&quot;, n = 1000)
wi2 &lt;- search_users(&quot;journalist wired&quot;, n = 1000)
wi3 &lt;- search_users(&quot;producer wired&quot;, n = 1000)
wi4 &lt;- search_users(&quot;designer wired&quot;, n = 1000)
wi5 &lt;- search_users(&quot;editor wired&quot;, n = 1000)
wi6 &lt;- search_users(&quot;writer wired&quot;, n = 1000)
wi7 &lt;- search_users(&quot;analyst wired&quot;, n = 1000)
wi8 &lt;- search_users(&quot;current wired&quot;, n = 1000)
wi9 &lt;- search_users(&quot;former wired&quot;, n = 1000)
wi10 &lt;- search_users(&quot;bylines wired&quot;, n = 1000)
wi11 &lt;- search_users(&quot;columnist wired&quot;, n = 1000)
wi12 &lt;- search_users(&quot;freelance wired&quot;, n = 1000)
wi&lt;-rbind(wi1, wi2, wi3, wi4, wi5, wi6, wi7, wi8, wi9, wi10, wi11, wi12)
wi$outlet&lt;-&quot;Wired&quot;
rm(wi1, wi2, wi3, wi4, wi5, wi6, wi7, wi8, wi9, wi10, wi11, wi12)


nw1 &lt;- search_users(&quot;reporter thenextweb&quot;, n = 1000)
nw2 &lt;- search_users(&quot;journalist thenextweb&quot;, n = 1000)
nw3 &lt;- search_users(&quot;producer thenextweb&quot;, n = 1000)
nw4 &lt;- search_users(&quot;designer thenextweb&quot;, n = 1000)
nw5 &lt;- search_users(&quot;editor thenextweb&quot;, n = 1000)
nw6 &lt;- search_users(&quot;writer thenextweb&quot;, n = 1000)
nw7 &lt;- search_users(&quot;analyst thenextweb&quot;, n = 1000)
nw8 &lt;- search_users(&quot;current thenextweb&quot;, n = 1000)
nw9 &lt;- search_users(&quot;former thenextweb&quot;, n = 1000)
nw10 &lt;- search_users(&quot;bylines thenextweb&quot;, n = 1000)
nw11 &lt;- search_users(&quot;columnist thenextweb&quot;, n = 1000)
nw12 &lt;- search_users(&quot;freelance thenextweb&quot;, n = 1000)
nw&lt;-rbind(nw1, nw2, nw3, nw4, nw5, nw6, nw7, nw8, nw9, nw10, nw11, nw12)
nw$outlet&lt;-&quot;The Next Web&quot;
rm(nw1, nw2, nw3, nw4, nw5, nw6, nw7, nw8, nw9, nw10, nw11, nw12)


gm1 &lt;- search_users(&quot;reporter gizmodo&quot;, n = 1000)
gm2 &lt;- search_users(&quot;journalist gizmodo&quot;, n = 1000)
gm3 &lt;- search_users(&quot;producer gizmodo&quot;, n = 1000)
gm4 &lt;- search_users(&quot;designer gizmodo&quot;, n = 1000)
gm5 &lt;- search_users(&quot;editor gizmodo&quot;, n = 1000)
gm6 &lt;- search_users(&quot;writer gizmodo&quot;, n = 1000)
gm7 &lt;- search_users(&quot;analyst gizmodo&quot;, n = 1000)
gm8 &lt;- search_users(&quot;current gizmodo&quot;, n = 1000)
gm9 &lt;- search_users(&quot;former gizmodo&quot;, n = 1000)
gm10 &lt;- search_users(&quot;bylines gizmodo&quot;, n = 1000)
gm11 &lt;- search_users(&quot;columnist gizmodo&quot;, n = 1000)
gm12 &lt;- search_users(&quot;freelance gizmodo&quot;, n = 1000)
gm&lt;-rbind(gm1, gm2, gm3, gm4, gm5, gm6, gm7, gm8, gm9, gm10, gm11, gm12)
gm$outlet&lt;-&quot;Gizmodo&quot;
rm(gm1, gm2, gm3, gm4, gm5, gm6, gm7, gm8, gm9, gm10, gm11, gm12)

cn1 &lt;- search_users(&quot;reporter cnet&quot;, n = 1000)
cn2 &lt;- search_users(&quot;journalist cnet&quot;, n = 1000)
cn3 &lt;- search_users(&quot;producer cnet&quot;, n = 1000)
cn4 &lt;- search_users(&quot;designer cnet&quot;, n = 1000)
cn5 &lt;- search_users(&quot;editor cnet&quot;, n = 1000)
cn6 &lt;- search_users(&quot;writer cnet&quot;, n = 1000)
cn7 &lt;- search_users(&quot;analyst cnet&quot;, n = 1000)
cn8 &lt;- search_users(&quot;current cnet&quot;, n = 1000)
cn9 &lt;- search_users(&quot;former cnet&quot;, n = 1000)
cn10 &lt;- search_users(&quot;bylines cnet&quot;, n = 1000)
cn11 &lt;- search_users(&quot;columnist cnet&quot;, n = 1000)
cn12 &lt;- search_users(&quot;freelance cnet&quot;, n = 1000)
cn&lt;-rbind(cn1, cn2, cn3, cn4, cn5, cn6, cn7, cn8, cn9, cn10, cn11, cn12)
cn$outlet&lt;-&quot;Cnet&quot;
rm(cn1, cn2, cn3, cn4, cn5, cn6, cn7, cn8, cn9, cn10, cn11, cn12)

tr1 &lt;- search_users(&quot;reporter techradar&quot;, n = 1000)
tr2 &lt;- search_users(&quot;journalist techradar&quot;, n = 1000)
tr3 &lt;- search_users(&quot;producer techradar&quot;, n = 1000)
tr4 &lt;- search_users(&quot;designer techradar&quot;, n = 1000)
tr5 &lt;- search_users(&quot;editor techradar&quot;, n = 1000)
tr6 &lt;- search_users(&quot;writer techradar&quot;, n = 1000)
tr7 &lt;- search_users(&quot;analyst techradar&quot;, n = 1000)
tr8 &lt;- search_users(&quot;current techradar&quot;, n = 1000)
tr9 &lt;- search_users(&quot;former techradar&quot;, n = 1000)
tr10 &lt;- search_users(&quot;bylines techradar&quot;, n = 1000)
tr11 &lt;- search_users(&quot;columnist techradar&quot;, n = 1000)
tr12 &lt;- search_users(&quot;freelance techradar&quot;, n = 1000)
tr&lt;-rbind(tr1, tr2, tr3, tr4, tr5, tr6, tr7, tr8, tr9, tr10, tr11, tr12)
tr$outlet&lt;-&quot;TechRadar&quot;
rm(tr1, tr2, tr3, tr4, tr5, tr6, tr7, tr8, tr9, tr10, tr11, tr12)

ti1 &lt;- search_users(&quot;reporter theinformation&quot;, n = 1000)
ti2 &lt;- search_users(&quot;journalist theinformation&quot;, n = 1000)
ti3 &lt;- search_users(&quot;producer theinformation&quot;, n = 1000)
ti4 &lt;- search_users(&quot;designer theinformation&quot;, n = 1000)
ti5 &lt;- search_users(&quot;editor theinformation&quot;, n = 1000)
ti6 &lt;- search_users(&quot;writer theinformation&quot;, n = 1000)
ti7 &lt;- search_users(&quot;analyst theinformation&quot;, n = 1000)
ti8 &lt;- search_users(&quot;current theinformation&quot;, n = 1000)
ti9 &lt;- search_users(&quot;former theinformation&quot;, n = 1000)
ti10 &lt;- search_users(&quot;bylines theinformation&quot;, n = 1000)
ti11 &lt;- search_users(&quot;columnist theinformation&quot;, n = 1000)
ti12 &lt;- search_users(&quot;freelance theinformation&quot;, n = 1000)
ti&lt;-rbind(ti1, ti2, ti3, ti4, ti5, ti6, ti7, ti8, ti9, ti10, ti11, ti12)
ti$outlet&lt;-&quot;The Information&quot;
rm(ti1, ti2, ti3, ti4, ti5, ti6, ti7, ti8, ti9, ti10, ti11, ti12)

tc1 &lt;- search_users(&quot;reporter techcrunch&quot;, n = 1000)
tc2 &lt;- search_users(&quot;journalist techcrunch&quot;, n = 1000)
tc3 &lt;- search_users(&quot;producer techcrunch&quot;, n = 1000)
tc4 &lt;- search_users(&quot;designer techcrunch&quot;, n = 1000)
tc5 &lt;- search_users(&quot;editor techcrunch&quot;, n = 1000)
tc6 &lt;- search_users(&quot;writer techcrunch&quot;, n = 1000)
tc7 &lt;- search_users(&quot;analyst techcrunch&quot;, n = 1000)
tc8 &lt;- search_users(&quot;current techcrunch&quot;, n = 1000)
tc9 &lt;- search_users(&quot;former techcrunch&quot;, n = 1000)
tc10 &lt;- search_users(&quot;bylines techcrunch&quot;, n = 1000)
tc11 &lt;- search_users(&quot;columnist techcrunch&quot;, n = 1000)
tc12 &lt;- search_users(&quot;freelance techcrunch&quot;, n = 1000)
tc&lt;-rbind(tc1, tc2, tc3, tc4, tc5, tc6, tc7, tc8, tc9, tc10, tc11, tc12)
tc$outlet&lt;-&quot;TechCrunch&quot;
rm(tc1, tc2, tc3, tc4, tc5, tc6, tc7, tc8, tc9, tc10, tc11, tc12)

rc1 &lt;- search_users(&quot;reporter recode&quot;, n = 1000)
rc2 &lt;- search_users(&quot;journalist recode&quot;, n = 1000)
rc3 &lt;- search_users(&quot;producer recode&quot;, n = 1000)
rc4 &lt;- search_users(&quot;designer recode&quot;, n = 1000)
rc5 &lt;- search_users(&quot;editor recode&quot;, n = 1000)
rc6 &lt;- search_users(&quot;writer recode&quot;, n = 1000)
rc7 &lt;- search_users(&quot;analyst recode&quot;, n = 1000)
rc8 &lt;- search_users(&quot;current recode&quot;, n = 1000)
rc9 &lt;- search_users(&quot;former recode&quot;, n = 1000)
rc10 &lt;- search_users(&quot;bylines recode&quot;, n = 1000)
rc11 &lt;- search_users(&quot;columnist recode&quot;, n = 1000)
rc12 &lt;- search_users(&quot;freelance recode&quot;, n = 1000)
rc&lt;-rbind(rc1, rc2, rc3, rc4, rc5, rc6, rc7, rc8, rc9, rc10, rc11, rc12)
rc$outlet&lt;-&quot;Recode&quot;
rm(rc1, rc2, rc3, rc4, rc5, rc6, rc7, rc8, rc9, rc10, rc11, rc12)

mb1 &lt;- search_users(&quot;reporter motherboard&quot;, n = 1000)
mb2 &lt;- search_users(&quot;journalist motherboard&quot;, n = 1000)
mb3 &lt;- search_users(&quot;producer motherboard&quot;, n = 1000)
mb4 &lt;- search_users(&quot;designer motherboard&quot;, n = 1000)
mb5 &lt;- search_users(&quot;editor motherboard&quot;, n = 1000)
mb6 &lt;- search_users(&quot;writer motherboard&quot;, n = 1000)
mb7 &lt;- search_users(&quot;analyst motherboard&quot;, n = 1000)
mb8 &lt;- search_users(&quot;current motherboard&quot;, n = 1000)
mb9 &lt;- search_users(&quot;former motherboard&quot;, n = 1000)
mb10 &lt;- search_users(&quot;bylines motherboard&quot;, n = 1000)
mb11 &lt;- search_users(&quot;columnist motherboard&quot;, n = 1000)
mb12 &lt;- search_users(&quot;freelance motherboard&quot;, n = 1000)
mb&lt;-rbind(mb1, mb2, mb3, mb4, mb5, mb6, mb7, mb8, mb9, mb10, mb11, mb12)
mb$outlet&lt;-&quot;Motherboard&quot;
rm(mb1, mb2, mb3, mb4, mb5, mb6, mb7, mb8, mb9, mb10, mb11, mb12)

nyt &lt;- search_users(&quot;tech nytimes&quot;, n = 1000)

# All the twitter usernames of authors who appeared in the Technology section
# of the NYT in the month of July

nyt2&lt;-lookup_users(c(&quot;sheeraf&quot;, &quot;daveyalba&quot;, &quot;ceciliakang&quot;, &quot;jacknicas&quot;, &quot;dmccabe&quot;,
               &quot;ShiraOvide&quot;, &quot;brooksbarnesNYT&quot;, &quot;nicsperling&quot;, &quot;noamscheiber&quot;,
               &quot;TaylorLorenz&quot;, &quot;hudidi1&quot;, &quot;ellenrosen&quot;, &quot;antontroian&quot;, &quot;jtes&quot;,
               &quot;VVFriedman&quot;, &quot;LizziePaton&quot;, &quot;kevinroose&quot;, &quot;JordanSalama19&quot;,
               &quot;maureendowd&quot;, &quot;daiwaka&quot;, &quot;smbahr14&quot;, &quot;JoannPlockova&quot;, &quot;m_delamerced&quot;,
               &quot;eringriffith&quot;, &quot;edmundlee&quot;, &quot;wendyluwrites&quot;, &quot;LoosLips&quot;, &quot;SteveLohr&quot;,
               &quot;jdbiersdorfer&quot;, &quot;katiehafner&quot;, &quot;nealboudette&quot;, &quot;choesanghun&quot;, &quot;portereduardo&quot;,
               &quot;Aaron_Krolik&quot;, &quot;zhonggg&quot;, &quot;AnaSwanson&quot;, &quot;nathanielpopper&quot;, &quot;ericmargolis&quot;,
               &quot;heathertal&quot;, &quot;MikeIsaac&quot;, &quot;charlie_savage&quot;, &quot;katie_thomas&quot;, &quot;mega2e&quot;,
               &quot;pnstenquist&quot;, &quot;byJenAMiller&quot;, &quot;SangerNYT&quot;, &quot;jakesNYT&quot;, &quot;veronica_penney&quot;,
               &quot;Lollardfish&quot;, &quot;satariano&quot;, &quot;_StephenCastle&quot;, &quot;kchangnyt&quot;, &quot;jwherrman&quot;,
               &quot;NYTnickc&quot;, &quot;NellieBowles&quot;, &quot;teddytinson&quot;, &quot;tiffkhsu&quot;, &quot;ezra_marc&quot;,
               &quot;Jonesieman&quot;, &quot;jmorrisseynyc&quot;, &quot;Lattif&quot;, &quot;pranshuverma_&quot;, &quot;ewong&quot;,
               &quot;bencareynyt&quot;, &quot;jonah_kessel&quot;, &quot;nicoleperlroth&quot;))

nyt&lt;-rbind(nyt, nyt2)
nyt$outlet &lt;- &quot;New York Times&quot;

# Remove duplicates within the NYT
nyt &lt;- nyt %&gt;% distinct(screen_name, outlet, .keep_all=T)

# Combine all journalists into one dataframe
df&lt;-rbind(v, go, e, vb, wi, nw, gm, cn, tr, ti, tc, rc, mb, nyt)

# ReadWrite, ForbesTech, and TechDirt were queried but excluded because
# each one had fewer than ten results.

# Restrict to English language accounts
df &lt;- df %&gt;%
  filter(lang==&quot;en&quot;) %&gt;%
  select(screen_name, name, location, description, followers_count, friends_count,
         listed_count,  statuses_count, favourites_count,   account_created_at, verified,
         profile_expanded_url,profile_image_url,outlet) %&gt;%
  distinct()

# Standardize and export for manual inspection

# journos &lt;- apply(df,2,as.character)

# write.csv(df, &quot;journos.intermediate.csv&quot;)</code></pre>
<p>The total number of accounts identified in this fashion was 1865, including some false positives such as generic brand entities or irrelevant coincidences. So we manually went through the results and narrowed the dataset down. We then conducted the subjective assignment of race and gender. We also standardized names and removed emojis in preparation for the next stage of analysis. This process left 982 individuals. There are a few duplicates (people who have written for multiple tech journalism outlets), which we retain for our diversity analysis at the outlet-level. We remove duplicates otherwise.</p>
<pre class="r"><code># Load the manually cleaned spreadsheet

# df&lt;-read.csv(&quot;/Users/justin/Dropbox/Public/journos.intermediate.csv&quot;)

# Calculate percent white within each tech journalism outlet
totals.subjective&lt;-df %&gt;%
  drop_na(subjective_race) %&gt;%
  group_by(outlet, subjective_race) %&gt;%
  summarise(n = n()) %&gt;%
  mutate(Percent = n / sum(n)) %&gt;%
  filter(subjective_race==&quot;White&quot;)

# Calculate the grand mean across outlets
# mean(totals.subjective$Percent)

# Prepare a dataframe to make the main featured graph
main.graph.df&lt;-df %&gt;%
  drop_na(subjective_race) %&gt;%
  group_by(outlet, subjective_race) %&gt;%
  summarise(n = n()) %&gt;%
  mutate(Percent = n / sum(n)) %&gt;%
  filter(subjective_race==&quot;White&quot;) %&gt;%
  select(outlet, Percent) %&gt;%
  mutate(Percent = Percent*100)

# Add tech company workforces stats
outlet&lt;-c(&quot;Facebook&quot;, &quot;Google&quot;, &quot;Microsoft&quot;, &quot;Amazon&quot;, &quot;Apple&quot;)
Percent&lt;-c(63.2, 51.7, 53.2, 34.7, 50)
tech.df&lt;-as.data.frame(cbind(outlet, Percent))
tech.df$Percent&lt;-as.numeric(levels(tech.df$Percent))[tech.df$Percent]

# Wrangle the two together
main.graph.df&lt;-bind_rows(main.graph.df, tech.df)

main.graph.df$Type &lt;- NA
main.graph.df$Type[1:14] &lt;- &quot;Tech Journalism&quot;
main.graph.df$Type[15:19] &lt;- &quot;Tech Companies&quot;

# Create main featured graph
main.graph.df %&gt;%
  ggplot(aes(x=fct_reorder(outlet, Percent), y=Percent, colour=Type)) +
  geom_point(size=4) +
  coord_flip() +
  theme_bw(base_size = 16) +
  labs(x=&quot;&quot;, y=&quot;Percent White&quot;) +
       #title=&quot;Tech Journalism Is Less Diverse Than Tech&quot;,
       #subtitle = &quot;Percent white, tech journalists vs. tech companies&quot;) +
       theme(legend.position=&quot;bottom&quot;) +
       theme(legend.title=element_blank()) +
  scale_y_continuous(breaks = seq(0, 100, by = 10), limits=(c(0,100)))</code></pre>
<p><img src="/post/2020-07-28-tech-journalism_files/figure-html/analysis-sample-1-1.png" width="672" /></p>
<pre class="r"><code># Visualize overall stats for subjectively assigned race
df %&gt;%
  drop_na(subjective_gender) %&gt;%
  group_by(outlet, subjective_gender) %&gt;%
  summarise(n = n()) %&gt;%
  mutate(Percent = n / sum(n)) %&gt;%
  filter(subjective_gender==&quot;Male&quot;) %&gt;%
  ggplot(aes(x=fct_reorder(outlet, Percent), y=Percent)) +
  geom_point(color = &quot;#9124b5&quot;) +
  coord_flip() +
  theme_bw() +
  labs(x=&quot;&quot;, y=&quot;Proportion Male&quot;,
       title=&quot;Gender Diversity Across 13 Major Tech-Journalism Outlets&quot;,
       subtitle = &quot;Race inferred by subjective judgment.&quot;,
       caption= &quot;By Justin Murphy (jmrphy.net, @jmrphy).&quot;)</code></pre>
<p><img src="/post/2020-07-28-tech-journalism_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code># Calculate overall stats for subjectively assigned gender
# summary(df$subjective_gender)</code></pre>
<p>According to our subjective judgment, 654 are likely White, 127 Asian, 23 Black, and 11 Hispanic.</p>
<p>Also according to our subjective judgment, 548 are Male and 372 are Female.</p>
<p>Next we leverage the <a href="https://cran.r-project.org/web/packages/predictrace/vignettes/Predict-race-of-surname.html"><em>predictrace</em></a> package to infer race from surnames, based on the co-occurrence of surnames and self-reported races in the Census datasets.</p>
<pre class="r"><code># Use names and publicly available datasets to infer race and gender non-subjectively

# Extract surname from the full name
df$lastnames &lt;- word(df$name,-1)
# Predict race from surname
race.profiles.df&lt;-predict_race(df$lastnames)

# To partially mitigate the problem of under-identifying black people,
# any surname with a probability of being black greater than .4 will
# will be classified as black. This will increase the error rate of
# classifying white people as black, but decrease the error rate of
# classifying black people as white.

race.profiles.df$likely_race&lt;-ifelse(race.profiles.df$probability_black&gt;.4 &amp;
         race.profiles.df$likely_race==&quot;white&quot;,
       &quot;black&quot;,
       race.profiles.df$likely_race)

# I think there&#39;s a bug in the predictrace package which fails
# to infer Hispanic race even when it identifies a very high probability
# of being Hispanic. I&#39;m correcting this manually by inferring
# Hispanic race for any probability greater than .5.

race.profiles.df$likely_race&lt;-ifelse(race.profiles.df$probability_hispanic&gt;.5,
       &quot;hispanic&quot;,
       race.profiles.df$likely_race)


# Bind predicted race variables to Twitter profiles
df &lt;- cbind(df, race.profiles.df$likely_race)
# Rename the inferred race variable
df$race &lt;- df$`race.profiles.df$likely_race`

# Extract first name from the full name
df$firstnames&lt;-word(df$name,1)
# Predict gender from first name
gender.profiles.df&lt;-gender(df$firstnames)
# Rename the inferred gender variable
gender.profiles.df$firstnames&lt;-gender.profiles.df$name
# Merge gender variables with Twitter profiles
df&lt;-merge(df, select(gender.profiles.df, gender, firstnames), by=&quot;firstnames&quot;, all.x=T)
# Remove duplicates created in merge
df&lt;-distinct(df)
# Remove redundant columns
df&lt;-select(df, -c(firstnames, lastnames, `race.profiles.df$likely_race`))

df$race&lt;-recode(df$race, asian = &quot;Asian&quot;,
                        black = &quot;Black&quot;,
                        white = &quot;White&quot;,
                        hispanic = &quot;Hispanic&quot;,
                        american_indian = &quot;American Indian&quot;)
# summary(df$race)

# Export final spreadsheet (this is the one you can download)

# write.csv(df, &quot;/Users/justin/Dropbox/Public/journos.csv&quot;)</code></pre>
<pre class="r"><code>totals.objective&lt;-df %&gt;%
  drop_na(race) %&gt;%
  group_by(outlet, race) %&gt;%
  summarise(n = n()) %&gt;%
  mutate(Percent = n / sum(n)) %&gt;%
  filter(race==&quot;White&quot;)

# mean(totals.objective$Percent)

df %&gt;%
  drop_na(race) %&gt;%
  group_by(outlet, race) %&gt;%
  summarise(n = n()) %&gt;%
  mutate(Percent = n / sum(n)) %&gt;%
  filter(race==&quot;White&quot;) %&gt;%
  ggplot(aes(x=fct_reorder(outlet, Percent), y=Percent)) +
  geom_point(color = &quot;#9124b5&quot;) +
  coord_flip() +
  theme_bw() +
  labs(x=&quot;&quot;, y=&quot;Percent White&quot;,
       title=&quot;Racial Diversity Across 13 Major Tech-Journalism Outlets&quot;,
       subtitle = &quot;Race inferred from surnames using Census Data.&quot;,
       caption= &quot;By Justin Murphy (jmrphy.net, @jmrphy).&quot;)</code></pre>
<p><img src="/post/2020-07-28-tech-journalism_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>According to this automated data-driven method, 471 are likely White, 67 Asian, 25 Black, 30 Hispanic, and 1 American Indian. (We did not code for American Indian when we did the subjective assessment.) The rest could not be classified. The White percentage is still very close to our estimates based on subjective assessments: About 77%.</p>
<pre class="r"><code>df %&gt;%
drop_na(race) %&gt;%
ggplot(aes(x = race)) +  
  geom_bar(aes(y = (..count..)/sum(..count..)), fill = &quot;#9124b5&quot;) +
  theme_bw() +
  labs(title=&quot;Racial Diversity Among Tech Journalists on Twitter&quot;,
       subtitle=&quot;Race inferred from surname using Census data. N=521.&quot;,
      x=&quot;&quot;,
       y=&quot;Proportion&quot;,
      caption=&quot;By Justin Murphy (jmrphy.net, @jmrphy)&quot;) +
  coord_flip()</code></pre>
<p><img src="/post/2020-07-28-tech-journalism_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Setting aside outlets, below is the graph for the distribution of race according to our subjective assessments of race.</p>
<pre class="r"><code>df %&gt;%
drop_na(subjective_race) %&gt;%
ggplot(aes(x = subjective_race)) +  
  geom_bar(aes(y = (..count..)/sum(..count..)), fill = &quot;#9124b5&quot;) +
  theme_bw() +
  labs(title=&quot;Racial Diversity Among Tech Journalists on Twitter&quot;,
       subtitle=&quot;Race inferred by subjective judgment. N=696.&quot;,
      x=&quot;&quot;,
       y=&quot;Proportion&quot;,
      caption=&quot;By Justin Murphy (jmrphy.net, @jmrphy).&quot;) +
  coord_flip()</code></pre>
<p><img src="/post/2020-07-28-tech-journalism_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>And then we leverage the <a href="https://cran.r-project.org/web/packages/gender/vignettes/predicting-gender.html"><em>gender</em></a> package to infer gender from first names, based on the co-occurrence of baby names and gender in the Social Security Administration datasets.</p>
<pre class="r"><code># Graph of gender diversity in Sample 1
df %&gt;%
drop_na(gender) %&gt;%
ggplot(aes(x = gender)) +  
  geom_bar(aes(y = (..count..)/sum(..count..)), fill = &quot;#9124b5&quot;) +
  theme_bw() +
  labs(title=&quot;Gender Diversity Among Tech Journalists on Twitter&quot;,
       subtitle=&quot;Gender inferred from first name using SSA data. N=806.&quot;,
      x=&quot;&quot;,
       y=&quot;Proportion&quot;,
      caption=&quot;By Justin Murphy (jmrphy.net, @jmrphy).&quot;) +
  coord_flip()</code></pre>
<p><img src="/post/2020-07-28-tech-journalism_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>df %&gt;%
drop_na(gender, race) %&gt;%
ggplot(aes(x = race)) +  
  geom_bar(aes(y = (..count..)/sum(..count..)), fill = &quot;#9124b5&quot;) +
  theme_bw() +
  labs(title=&quot;Racial and Gender Diversity Among Tech Journalists on Twitter&quot;,
       subtitle=&quot;Race and gender inferred from names using government data. N=500.&quot;,
      x=&quot;&quot;,
       y=&quot;Proportion&quot;,
      caption=&quot;By Justin Murphy (jmrphy.net, @jmrphy).&quot;) +
  coord_flip() + facet_wrap(.~gender)</code></pre>
<p><img src="/post/2020-07-28-tech-journalism_files/figure-html/unnamed-chunk-7-2.png" width="672" /></p>
<pre class="r"><code>df %&gt;%
drop_na(subjective_gender) %&gt;%
ggplot(aes(x = subjective_gender)) +  
  geom_bar(aes(y = (..count..)/sum(..count..)), fill = &quot;#9124b5&quot;) +
  theme_bw() +
  labs(title=&quot;Gender Diversity Among Tech Journalists on Twitter&quot;,
       subtitle=&quot;Gender inferred by subjective judgment. N=794.&quot;,
      x=&quot;&quot;,
       y=&quot;Proportion&quot;,
      caption=&quot;By Justin Murphy (jmrphy.net, @jmrphy).&quot;) +
  coord_flip()</code></pre>
<p><img src="/post/2020-07-28-tech-journalism_files/figure-html/unnamed-chunk-7-3.png" width="672" /></p>
<pre class="r"><code>df %&gt;%
drop_na(subjective_gender, subjective_race) %&gt;%
ggplot(aes(x = subjective_race)) +  
  geom_bar(aes(y = (..count..)/sum(..count..)), fill = &quot;#9124b5&quot;) +
  theme_bw() +
  labs(title=&quot;Racial and Gender Diversity Among Tech Journalists on Twitter&quot;,
       subtitle=&quot;Race and gender inferred by subjective judgment..&quot;,
      x=&quot;&quot;,
       y=&quot;Proportion&quot;,
      caption=&quot;By Justin Murphy (jmrphy.net, @jmrphy).&quot;) +
  coord_flip() + facet_wrap(.~subjective_gender)</code></pre>
<p><img src="/post/2020-07-28-tech-journalism_files/figure-html/unnamed-chunk-7-4.png" width="672" /></p>
<pre class="r"><code>df %&gt;%
  drop_na(race) %&gt;%
  group_by(outlet, race) %&gt;%
  summarise(n = n()) %&gt;%
  mutate(Percent = n / sum(n)) %&gt;%
  filter(race==&quot;White&quot;) %&gt;%
  ggplot(aes(x=fct_reorder(outlet, Percent), y=Percent)) +
  geom_point(color = &quot;#9124b5&quot;) +
  coord_flip() +
  theme_bw() +
  labs(x=&quot;&quot;, y=&quot;Percent White&quot;,
       title=&quot;Racial Diversity Across 13 Major Tech-Journalism Outlets&quot;,
       subtitle = &quot;Race inferred from surnames using government data.&quot;,
       caption= &quot;By Justin Murphy (jmrphy.net, @jmrphy).&quot;)</code></pre>
<p><img src="/post/2020-07-28-tech-journalism_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<pre class="r"><code># summary(df$subjective_race)

df %&gt;%
  drop_na(gender) %&gt;%
  group_by(outlet, gender) %&gt;%
  summarise(n = n()) %&gt;%
  mutate(Percent = n / sum(n)) %&gt;%
  filter(gender==&quot;Male&quot;) %&gt;%
  ggplot(aes(x=fct_reorder(outlet, Percent), y=Percent)) +
  geom_point(color = &quot;#9124b5&quot;) +
  coord_flip() +
  theme_bw() +
  labs(x=&quot;&quot;, y=&quot;Percent Male&quot;,
       title=&quot;Gender Diversity Across 13 Major Tech-Journalism Outlets&quot;,
       subtitle = &quot;Gender inferred by subjective judgment. N=794.&quot;,
       caption= &quot;By Justin Murphy (jmrphy.net, @jmrphy).&quot;)</code></pre>
<p><img src="/post/2020-07-28-tech-journalism_files/figure-html/unnamed-chunk-8-2.png" width="672" /></p>
</div>
<div id="approach-2-curated-lists-of-tech-journalists" class="section level2">
<h2>Approach 2: Curated lists of “tech journalists”</h2>
<p>I found two Twitter lists entitled “Tech Journalists” (<a href="https://twitter.com/i/lists/96162061">1</a>, <a href="https://twitter.com/i/lists/53301954">2</a>). I take these at face value and combine all the listed Twitter accounts into a new sample of tech journalists. Then I re-run all of the analyses above on this new sample. The initial number of journalists in Sample 2 is 424; after removing duplicates the number is 360.</p>
<p>The basic counts are: 179 likely to be White, 17 likely to be Asian, 9 likely to be Black, and 8 likely to be Hispanic. The rest could not be classified.</p>
<p>The result is very close to our previous results, again: 84% White.</p>
<pre class="r"><code># Import the accounts identified by each list
journo.list1&lt;-lists_members(96162061)
journo.list2&lt;-lists_members(53301954)

# Bind them into one dataframe
df2&lt;-rbind(journo.list1, journo.list2)

# Extract surname and predict race
df2$lastnames&lt;-word(df2$name,-1)
race.lists.df&lt;-predict_race(df2$lastnames)

# To partially mitigate the problem of under-identifying black people,
# any surname with a probability of being black greater than .4 will
# will be classified as black. This will increase the error rate of
# classifying white people as black, but decrease the error rate of
# classifying black people as white.

race.lists.df$likely_race&lt;-ifelse(race.lists.df$probability_black&gt;.4 &amp;
         race.lists.df$likely_race==&quot;white&quot;,
       &quot;black&quot;,
       race.lists.df$likely_race)

# I think there&#39;s a bug in the predictrace package which fails
# to infer Hispanic race even when it identifies a very high probability
# of being Hispanic. I&#39;m mitigating this manually by inferring
# Hispanic race for any probability greater than .5.

race.lists.df$likely_race&lt;-ifelse(race.lists.df$probability_hispanic&gt;.5,
       &quot;hispanic&quot;,
       race.lists.df$likely_race)

df2$race&lt;-race.lists.df$likely_race

# Extract first name and predict gender
df2$firstnames&lt;-word(df2$name,1)
gender.lists.df&lt;-gender(df2$firstnames)
gender.lists.df$firstnames&lt;-gender.lists.df$name

# Merge and remove duplicates
df2&lt;-merge(df2, gender.lists.df, by=&quot;firstnames&quot;)
df2&lt;-distinct(df2)

# Fix capitalization
df2$race&lt;-recode(df2$race, asian = &quot;Asian&quot;,
                        black = &quot;Black&quot;,
                        white = &quot;White&quot;,
                        hispanic = &quot;Hispanic&quot;)

# Export
# write.csv(df2, &quot;/Users/justin/Dropbox/Public/tech-journalists-from-lists-df.csv&quot;)

# Total percentages from lists
totals.from.lists&lt;-df2 %&gt;%
  drop_na(race) %&gt;%
  group_by(race) %&gt;%
  summarise(n = n()) %&gt;%
  mutate(Percent = n / sum(n)) %&gt;%
  filter(race==&quot;White&quot;)

df2 %&gt;%
drop_na(race) %&gt;%
ggplot(aes(x = race)) +  
  geom_bar(aes(y = (..count..)/sum(..count..)), fill = &quot;#9124b5&quot;) +
  theme_bw() +
  labs(title=&quot;Racial Diversity Among Tech Journalists on Twitter&quot;,
       subtitle=&quot;Sample 2: Lists of tech journalists on Twitter, curated by third parties&quot;,
      x=&quot;Most likely race&quot;,
       y=&quot;Proportion&quot;) +
#      caption=&quot;Race is inferred from surname using Census data.\n By Justin Murphy #(jmrphy.net, @jmrphy)&quot;) +
  coord_flip()</code></pre>
<p>Using the third-party Twitter lists of tech journalists and inferring race surnames suggests that tech journalists are 84% White.</p>
<pre class="r"><code>df2 %&gt;%
drop_na(gender) %&gt;%
ggplot(aes(x = gender)) +  
  geom_bar(aes(y = (..count..)/sum(..count..)), fill = &quot;#9124b5&quot;) +
  theme_bw() +
  labs(title=&quot;Gender Diversity Among Tech Journalists on Twitter&quot;,
       subtitle=&quot;Sample 2: Lists of tech journalists on Twitter, curated by third parties&quot;,
      x=&quot;Most likely gender&quot;,
       y=&quot;Proportion&quot;,
      caption=&quot;Gender is inferred from Social Security Administration data. \n By Justin Murphy (jmrphy.net, @jmrphy)&quot;) +
  coord_flip()</code></pre>
<p><img src="/post/2020-07-28-tech-journalism_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code>df2 %&gt;%
drop_na(gender, race) %&gt;%
ggplot(aes(x = race)) +  
  geom_bar(aes(y = (..count..)/sum(..count..)), fill = &quot;#9124b5&quot;) +
  theme_bw() +
  labs(title=&quot;Racial and Gender Diversity Among Tech Journalists on Twitter&quot;,
       subtitle=&quot;Sample 2: Lists of tech journalists on Twitter, curated by third parties&quot;,
      x=&quot;Most likely race&quot;,
       y=&quot;Proportion&quot;,
      caption=&quot;Race is inferred from surname using Census data; gender from \n first name using Social Security Administration baby names. \n By Justin Murphy (jmrphy.net, @jmrphy)&quot;) +
  coord_flip() + facet_wrap(.~gender)</code></pre>
<p><img src="/post/2020-07-28-tech-journalism_files/figure-html/unnamed-chunk-9-2.png" width="672" /></p>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>The roughly similar distributions across two different sampling methods and two different measurement methods suggest the the results here are likely an accurate portrait of tech-journalism Twitter generally.</p>
<p>If you spot any errors, <a href="https://theotherlifenow.com/contact/">please contact me.</a></p>
</div>
